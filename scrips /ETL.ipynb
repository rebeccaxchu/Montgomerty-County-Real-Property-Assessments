{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOcOd+yjvx/xo2K1oLXJdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebeccaxchu/Real-Property-Assessments/blob/main/scrips%20/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuyCdTuk14SC",
        "outputId": "76d9d0bd-1043-4748-90ab-197b92610d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/394.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (42.0.5)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.11.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2024.2.2)\n",
            "Installing collected packages: isodate, azure-core, azure-storage-blob\n",
            "Successfully installed azure-core-1.30.1 azure-storage-blob-12.19.1 isodate-0.6.1\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.29)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-storage-blob\n",
        "!pip install pyarrow\n",
        "!pip install psycopg2 sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from google.cloud import storage\n",
        "from io import StringIO\n",
        "from math import ceil\n",
        "import datetime\n",
        "import calendar\n",
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "aK4-w8NP2Cdx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hISwShVC2dAy",
        "outputId": "4b84651a-2d81-4cf6-8953-93a24829a10f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the path to your JSON configuration file\n",
        "config_file_path= '/content/gdrive/MyDrive/Colab Notebooks/mdproperty/credentials.json'\n",
        "\n",
        "# load the JSON configuration file\n",
        "with open(config_file_path, 'r') as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "Connection_String_AZURE_STORAGE = config[\"ConnectionString\"]\n",
        "CONTAINER_AZURE= 'mdrealproperty'\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "pRNvAJ982k0B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Functions\n",
        "def azure_upload_blob(connect_str, container_name, blob_name, data):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    blob_client.upload_blob(data, overwrite=True)\n",
        "    print(f\"Uploaded to Azure Blob: {blob_name}\")\n",
        "\n",
        "def azure_download_blob(connect_str, container_name, blob_name):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    download_stream = blob_client.download_blob()\n",
        "    return download_stream.readall()"
      ],
      "metadata": {
        "id": "woJ0HJQp2OFl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the blobserviceclient\n",
        "blob_service_client = BlobServiceClient.from_connection_string(Connection_String_AZURE_STORAGE)\n",
        "\n",
        "#get the container client\n",
        "container_client = blob_service_client.get_container_client(CONTAINER_AZURE)\n",
        "\n",
        "md_property_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "ASWwvKbH2UHB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list all blobs in specified container\n",
        "blob_list = container_client.list_blobs()\n",
        "\n",
        "for blob in blob_list:\n",
        "  print(blob.name)\n",
        "  blob_client = container_client.get_blob_client(blob=blob.name)\n",
        "  blob_data = blob_client.download_blob()\n",
        "  blob_content = blob_data.readall().decode('utf-8')\n",
        "  df = pd.read_csv(StringIO(blob_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IepkkZOv4dYm",
        "outputId": "69cf5746-b47c-43f7-ba0b-585452c96d88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "property.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-81df1378b9d7>:9: DtypeWarning: Columns (21,47,89,124,166,173,178,186,199,201,203,206,207,208) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(StringIO(blob_content))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Display the head of the DataFrame\n",
        "  df.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vpferf540J9",
        "outputId": "8cf1aa40-50c3-40c7-8ca9-fa9f6984f510"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35228, 209)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # since I have only one csv, I am doing to do the following instructions\n",
        "md_property_df = df.copy()\n"
      ],
      "metadata": {
        "id": "9t8UlhQ45PDL"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}